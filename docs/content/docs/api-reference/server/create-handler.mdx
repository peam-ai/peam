---
title: createHandler
description: Create an API route handler for AI requests
---

# createHandler

Creates a Next.js API route handler that processes AI chat requests with any Vercel AI SDK model.

## Type Definition

{/* @skip-typecheck: incomplete type definition example */}

```typescript
import type { LanguageModelV1 } from 'ai';

export interface CreateHandlerOptions {
  /**
   * The AI model to use for generating responses
   * Can be any model from the Vercel AI SDK
   */
  model: LanguageModelV1;

  /**
   * Optional function to export search index data
   */
  searchIndexExporter?: () => Promise<SearchIndex>;
}

function createHandler(options: CreateHandlerOptions): (request: Request) => Promise<Response>;
```

## Usage

### Basic Usage

```typescript
import { createHandler } from 'peam/server';
import { openai } from '@ai-sdk/openai';

export const POST = createHandler({
  model: openai('gpt-4o'),
});
```

### With Anthropic

```typescript
import { createHandler } from 'peam/server';
import { anthropic } from '@ai-sdk/anthropic';

export const POST = createHandler({
  model: anthropic('claude-3-5-sonnet-20241022'),
});
```

### With Google

```typescript
import { createHandler } from 'peam/server';
import { google } from '@ai-sdk/google';

export const POST = createHandler({
  model: google('gemini-2.0-flash-exp'),
});
```

### With DeepSeek

```typescript
import { createHandler } from 'peam/server';
import { createOpenAI } from '@ai-sdk/openai';

const deepseek = createOpenAI({
  apiKey: process.env.DEEPSEEK_API_KEY,
  baseURL: 'https://api.deepseek.com',
});

export const POST = createHandler({
  model: deepseek('deepseek-chat'),
});
```

### With Custom Model

```typescript
import { createHandler } from 'peam/server';
import { openai } from '@ai-sdk/openai';

export const POST = createHandler({
  model: openai('gpt-5'), // Use any model supported by the SDK
});
```

### Full Example

```typescript
// app/api/chat/route.ts
import { createHandler } from 'peam/server';
import { openai } from '@ai-sdk/openai';

export const POST = createHandler({
  model: openai('gpt-4o'),
  searchIndexExporter: async () => {
    // Optional: provide custom search index
    return myCustomSearchIndex;
  },
});

export const runtime = 'edge'; // Optional: use Edge Runtime
```

## Supported Models

The `createHandler` function works with any model from the [Vercel AI SDK](https://sdk.vercel.ai/providers/ai-sdk-providers):

- **OpenAI**: GPT-4o, GPT-4, GPT-3.5, o1, o3-mini
- **Anthropic**: Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Haiku
- **Google**: Gemini 2.0 Flash, Gemini 1.5 Pro, Gemini 1.5 Flash
- **Mistral**: Mistral Large, Mistral Small, Codestral
- **Cohere**: Command R+, Command R
- **DeepSeek**: DeepSeek Chat, DeepSeek Coder
- **Custom providers**: Any compatible OpenAI-style API

## Parameters

| Parameter             | Type                         | Required | Description                  |
| --------------------- | ---------------------------- | -------- | ---------------------------- |
| `model`               | `LanguageModelV1`            | Yes      | AI model from Vercel AI SDK  |
| `searchIndexExporter` | `() => Promise<SearchIndex>` | No       | Custom search index provider |

## Return Value

Returns a Next.js API route handler function that can be exported as `POST`.

## Notes

- Automatically handles streaming responses
- Works with Next.js App Router (Route Handlers)
- Compatible with Edge Runtime
- No vendor lock-in - switch models anytime
- Uses Vercel AI SDK for model abstraction
